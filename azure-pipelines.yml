# Build and JAR files or such and copy to artifacts folder
# Copy Git files to artifacts folder
# Deploy the ARM template
# 

trigger: none

parameters:
- name: GIT_NOTEBOOK_PATH
  displayName: Notebooks Relative Path in Git
  type: string
  default: 'notebooks/MyProject'

- name: NOTEBOOK_DEPLOYMENT_PATH
  displayName: Notebooks Deployment Path to Databricks
  type: string
  default: '/MyProject'

- name: RESOURCE_GROUP
  displayName: Resource Group Name
  type: string
  default: 'Databricks-MyProject'
  
- name: LOCATION
  displayName: Azure Region
  type: string
  default: 'EastUS2'
  values:
  - EastUS
  - EastUS2
  - Add-others-here

- name: WORKSPACE_NAME
  displayName: Databricks workspace name
  type: string
  default: 'Databricks-MyProject'

  # NOTE: You could make this a variable and then change the name to append the environment parameter above.  You would need to create a corrisponding service connection
  # e.g. If you connection is named "MyConnection", you would have MyConnection-Dev (for dev subscription), MyConnection-QA (etc...)
- name: RESOURCE_MANAGER_CONNECTION
  displayName: Azure Resource Connection Name
  type: string
  default: 'Microsoft Azure Adam Paternostro(00000000-0000-0000-0000-000000000000)'


stages:
#############################################################
# Build the code
# Currently this is not building and JAR files, but you would do that here
# This is packaging up the files from Git to the Artifacts files
#############################################################
- stage: Build
  jobs:
  - job: JobBuild
    displayName: 'Job Build'
    variables:
      solution: '**/*.sln'
      buildPlatform: 'Any CPU'
      buildConfiguration: 'Release'
    pool:
      vmImage: 'ubuntu-latest'

    steps:
      - task: PublishBuildArtifacts@1
        displayName: 'Publish Artifact: ARM-Templates'
        inputs:
          PathtoPublish: '$(Build.Repository.LocalPath)/ARM-Templates'
          ArtifactName: 'ARM-Templates'

      - task: PublishBuildArtifacts@1
        displayName: 'Publish Artifact: Databricks-Clusters'
        inputs:
          PathtoPublish: '$(Build.Repository.LocalPath)/clusters'
          ArtifactName: 'clusters'

      - task: PublishBuildArtifacts@1
        displayName: 'Publish Artifact: Databricks-Notebooks'
        inputs:
          PathtoPublish: '$(Build.Repository.LocalPath)/notebooks'
          ArtifactName: 'notebooks'

      - task: PublishBuildArtifacts@1
        displayName: 'Publish Artifact: Databricks-Init-Scripts'
        inputs:
          PathtoPublish: '$(Build.Repository.LocalPath)/init-scripts'
          ArtifactName: 'init-scripts'

      - task: PublishBuildArtifacts@1
        displayName: 'Publish Artifact: Databricks-Deployment-Scripts'
        inputs:
          PathtoPublish: '$(Build.Repository.LocalPath)/deployment-scripts'
          ArtifactName: 'deployment-scripts'


#############################################################
# Deploy to Dev
#############################################################
- stage: Staging
  jobs:
  - deployment: JobDev
    displayName: 'Job Dev'
    environment: 'Dev'
    pool:
      vmImage: 'ubuntu-latest'

    strategy:
      runOnce:
        deploy:  
          steps:
            - checkout: none

            ### Show all the environment variables ###
            - task: PowerShell@2
              displayName: "Current Environment Variables"
              inputs:
                targetType: 'inline'
                script: 'dir env:'

            - task: AzureResourceManagerTemplateDeployment@3
              displayName: "Deploy Databricks ARM Template"
              inputs:
                deploymentScope: 'Resource Group'
                azureResourceManagerConnection: ${{ parameters.RESOURCE_MANAGER_CONNECTION}}
                subscriptionId: ${{ parameters.SUBSCRIPTION_ID }}
                action: 'Create Or Update Resource Group'
                resourceGroupName: ${{ parameters.RESOURCE_GROUP }}-Dev
                location: ${{ parameters.LOCATION }}
                templateLocation: 'Linked artifact'
                csmFile: '$(Pipeline.Workspace)/ARM-Templates/azuredeploy.databricks.json'
                csmParametersFile: '$(Pipeline.Workspace)/ARM-Templates/parameters.databricks.json'
                overrideParameters: '-workspaceName ${{ parameters.WORKSPACE_NAME }}-Dev'
                deploymentMode: 'Incremental'

            - task: AzureResourceManagerTemplateDeployment@3
              displayName: "Deploy KeyVault ARM Template"
              inputs:
                deploymentScope: 'Resource Group'
                azureResourceManagerConnection: ${{ parameters.RESOURCE_MANAGER_CONNECTION}}
                subscriptionId: ${{ parameters.SUBSCRIPTION_ID }}
                action: 'Create Or Update Resource Group'
                resourceGroupName: ${{ parameters.RESOURCE_GROUP }}-Dev
                location: ${{ parameters.LOCATION }}
                templateLocation: 'Linked artifact'
                csmFile: '$(Pipeline.Workspace)/ARM-Templates/azuredeploy.keyvault.json'
                csmParametersFile: '$(Pipeline.Workspace)/ARM-Templates/parameters.keyvault.json'
                overrideParameters: '-workspaceName ${{ parameters.WORKSPACE_NAME }}-Dev'
                deploymentMode: 'Incremental'

            - task: AzureKeyVault@1
              displayName: "Download KeyVault Secrets"
              inputs:
                azureSubscription: 'Microsoft Azure Adam Paternostro(64a14e46-6c7d-4063-9665-c295287ab709)'
                KeyVaultName: 'AdamKeyVault'
                SecretsFilter: 'databricks_dev_ops_subscription_id,databricks_dev_ops_tenant_id,databricks_dev_ops_client_id,databricks_dev_ops_client_secret'
                RunAsPreJob: false

            - task: Bash@3
              displayName: "Deploy Databricks Init Scripts"
              # Only run if KeyVault has values set
              condition: ne($(databricks_dev_ops_tenant_id), 'PLEASE_SET_ME (e.g. 00000000-0000-0000-0000-000000000000)')
              inputs:
                filePath: '$(Pipeline.Workspace)/deployment-scripts/deploy-init-scripts.sh'
                arguments: '$(databricks_dev_ops_tenant_id) $(databricks_dev_ops_client_id) $(databricks_dev_ops_client_secret) $(databricks_dev_ops_subscription_id) ${{ parameters.RESOURCE_GROUP }}-Dev ${{ parameters.WORKSPACE_NAME }}-Dev'
                workingDirectory: '$(Pipeline.Workspace)/init-scripts'

            - task: Bash@3
              displayName: "Deploy Databricks Clusters"
              # Only run if KeyVault has values set
              condition: ne($(databricks_dev_ops_tenant_id), 'PLEASE_SET_ME (e.g. 00000000-0000-0000-0000-000000000000)')
              inputs:
                filePath: '$(Pipeline.Workspace)/deployment-scripts/deploy-clusters.sh'
                arguments: '$(databricks_dev_ops_tenant_id) $(databricks_dev_ops_client_id) $(databricks_dev_ops_client_secret) $(databricks_dev_ops_subscription_id) ${{ parameters.RESOURCE_GROUP }}-Dev ${{ parameters.WORKSPACE_NAME }}-Dev'
                workingDirectory: '$(Pipeline.Workspace)/clusters'

            - task: Bash@3
              displayName: "Deploy Databricks Notebooks"
              # Only run if KeyVault has values set
              condition: ne($(databricks_dev_ops_tenant_id), 'PLEASE_SET_ME (e.g. 00000000-0000-0000-0000-000000000000)')
              inputs:
                filePath: '$(Pipeline.Workspace)/deployment-scripts/deploy-notebooks.sh'
                arguments: '$(databricks_dev_ops_tenant_id) $(databricks_dev_ops_client_id) $(databricks_dev_ops_client_secret) $(databricks_dev_ops_subscription_id) ${{ parameters.RESOURCE_GROUP }}-Dev ${{ parameters.WORKSPACE_NAME }}-Dev ${{ parameters.NOTEBOOK_DEPLOYMENT_PATH }}'
                workingDirectory: '$(Pipeline.Workspace)/${{ parameters.GIT_NOTEBOOK_PATH }}'
